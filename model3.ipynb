{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2768030b",
   "metadata": {},
   "source": [
    "# Multimodal Late Fusion Model\n",
    "## Text + Tabular + Image embeddings -> SVM + XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5498683",
   "metadata": {},
   "source": [
    "## 0) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f23246ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Embedding, Bidirectional, LSTM,\n",
    "    Dense, Dropout, BatchNormalization,\n",
    "    GlobalAveragePooling1D, GlobalMaxPooling1D,\n",
    "    Concatenate\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a16b472",
   "metadata": {},
   "source": [
    "## 1) Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d9ea3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"FoodFactsCleaned.csv\")\n",
    "df[\"nutriscore_letter\"] = df[\"nutriscore_letter\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1abd7f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_COLS = [ \n",
    "    \"brand_cleaned\",\n",
    "    \"allergens_cleaned\",\n",
    "    \"ingredients_text_cleaned\",\n",
    "    \"countries_cleaned\",\n",
    "    \"additives_cleaned\",\n",
    "]\n",
    "\n",
    "TABULAR_COLS = [\n",
    "    'nova_group', 'fat_100g',\n",
    "    'saturated_fat_100g', 'carbohydrates_100g', 'sugars_100g', 'fiber_100g',\n",
    "    'proteins_100g', 'contains_palm_oil', 'vegetarian_status', 'vegan_status',\n",
    "    'nutrient_level_fat', 'nutrient_level_saturated_fat',\n",
    "    'nutrient_level_sugars', 'nutrient_level_salt', 'ecoscore_grade', 'ecoscore_score',\n",
    "    'carbon_footprint_100g', 'additives_count', 'sugar_ratio',\n",
    "    'energy_density', 'protein_ratio', 'macro_balance', 'healthy_score',\n",
    "    'log_energy_kcal_100g', 'log_salt_100g'\n",
    "]\n",
    "\n",
    "TARGET_COL = \"nutriscore_letter\"           \n",
    "IMAGE_COL = \"image_160_path\"\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# Text tokenization\n",
    "MAX_WORDS = 30000\n",
    "MAX_LEN = 200\n",
    "\n",
    "# Image settings\n",
    "IMG_SIZE = (160, 160)\n",
    "\n",
    "# NN training\n",
    "EPOCHS_TEXT = 10\n",
    "EPOCHS_TAB  = 25\n",
    "EPOCHS_IMG  = 10\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f4f1cf",
   "metadata": {},
   "source": [
    "## 2) Basic checks + building concatenated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfe39424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after filtering invalid image paths: 5138\n"
     ]
    }
   ],
   "source": [
    "needed = TEXT_COLS + TABULAR_COLS + [TARGET_COL, IMAGE_COL]\n",
    "missing = [c for c in needed if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns in df: {missing}\")\n",
    "\n",
    "for c in TEXT_COLS:\n",
    "    df[c] = df[c].fillna(\"\").astype(str)\n",
    "\n",
    "df[\"text_concat\"] = df[TEXT_COLS].agg(\" \".join, axis=1)\n",
    "\n",
    "df = df[df[IMAGE_COL].notna()].copy()\n",
    "df = df[df[IMAGE_COL].astype(str).str.len() > 0].copy()\n",
    "df = df[df[IMAGE_COL].apply(lambda p: os.path.exists(str(p)))].copy()\n",
    "\n",
    "print(\"Rows after filtering invalid image paths:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ef849e",
   "metadata": {},
   "source": [
    "## 3) Unified Data Splitting across Modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0c510b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: 5\n",
      "Train: 4110 Test: 1028\n"
     ]
    }
   ],
   "source": [
    "X_text = df[\"text_concat\"].values\n",
    "X_tab  = df[TABULAR_COLS].values.astype(np.float32)\n",
    "X_img  = df[IMAGE_COL].astype(str).values\n",
    "y_raw  = df[TARGET_COL].values\n",
    "\n",
    "if y_raw.dtype == object or isinstance(y_raw[0], str):\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y_raw)\n",
    "else:\n",
    "    y = y_raw.astype(int)\n",
    "\n",
    "num_classes = len(np.unique(y))\n",
    "print(\"Classes:\", num_classes)\n",
    "\n",
    "X_text_tr, X_text_te, X_tab_tr, X_tab_te, X_img_tr, X_img_te, y_tr, y_te = train_test_split(\n",
    "    X_text, X_tab, X_img, y,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", len(y_tr), \"Test:\", len(y_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05972b9",
   "metadata": {},
   "source": [
    "## Text & Tabular Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c77f7652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 14981\n",
      "Tab dim: 25\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_text_tr)\n",
    "\n",
    "seq_tr = tokenizer.texts_to_sequences(X_text_tr)\n",
    "seq_te = tokenizer.texts_to_sequences(X_text_te)\n",
    "\n",
    "X_text_tr_pad = pad_sequences(seq_tr, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "X_text_te_pad = pad_sequences(seq_te, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "vocab_size = min(MAX_WORDS, len(tokenizer.word_index) + 1)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_tab_tr_sc = scaler.fit_transform(X_tab_tr).astype(np.float32)\n",
    "X_tab_te_sc = scaler.transform(X_tab_te).astype(np.float32)\n",
    "\n",
    "tab_dim = X_tab_tr_sc.shape[1]\n",
    "print(\"Tab dim:\", tab_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b8420d",
   "metadata": {},
   "source": [
    "## Image loading & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2826c378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(path):\n",
    "    img_bytes = tf.io.read_file(path)\n",
    "    img = tf.io.decode_image(img_bytes, channels=3, expand_animations=False)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = mobilenet_preprocess(img)\n",
    "    return img\n",
    "\n",
    "def make_img_ds(paths, labels, batch_size=64, training=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "\n",
    "    def _map(p, y_):\n",
    "        return load_and_preprocess_image(p), y_\n",
    "    \n",
    "    ds = ds.map(_map, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if training:\n",
    "        ds = ds.shuffle(2048, seed=RANDOM_STATE, reshuffle_each_iteration=True)\n",
    "\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "img_train_ds = make_img_ds(X_img_tr, y_tr, batch_size=32, training=True)\n",
    "img_test_ds  = make_img_ds(X_img_te, y_te, batch_size=32, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb78601e",
   "metadata": {},
   "source": [
    "## 6) Modality-specific models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebc7bfc",
   "metadata": {},
   "source": [
    "### 6A) TEXT model: BiLSTM + pooling -> embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c0da18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_26\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_26\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ text_in             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_embed           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">958,784</span> │ text_in[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> │ txt_embed[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_gap             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ txt_rnn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_gmp             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ txt_rnn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_pool_concat     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ txt_gap[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ txt_gmp[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_embed_dense     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ txt_pool_concat[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ txt_embed_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │ dropout_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ text_in             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_embed           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │    \u001b[38;5;34m958,784\u001b[0m │ text_in[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │      \u001b[38;5;34m1,296\u001b[0m │ txt_embed[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_gap             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ txt_rnn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_gmp             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ txt_rnn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_pool_concat     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ txt_gap[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ txt_gmp[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_embed_dense     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m2,112\u001b[0m │ txt_pool_concat[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ txt_embed_dense[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_out (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │        \u001b[38;5;34m325\u001b[0m │ dropout_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">962,517</span> (3.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m962,517\u001b[0m (3.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">962,517</span> (3.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m962,517\u001b[0m (3.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 0.2156 - loss: 1.6173 - val_accuracy: 0.2652 - val_loss: 1.5874 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.3236 - loss: 1.5385 - val_accuracy: 0.4027 - val_loss: 1.4380 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 102ms/step - accuracy: 0.3963 - loss: 1.3827 - val_accuracy: 0.4672 - val_loss: 1.2676 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.4337 - loss: 1.2814 - val_accuracy: 0.4732 - val_loss: 1.2059 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 62ms/step - accuracy: 0.4857 - loss: 1.1754 - val_accuracy: 0.5182 - val_loss: 1.1532 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.5356 - loss: 1.0705 - val_accuracy: 0.5487 - val_loss: 1.1070 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.5633 - loss: 1.0241 - val_accuracy: 0.5523 - val_loss: 1.0795 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.6052 - loss: 0.9292 - val_accuracy: 0.5511 - val_loss: 1.0618 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.6363 - loss: 0.8646 - val_accuracy: 0.5572 - val_loss: 1.0618 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.6834 - loss: 0.7758 - val_accuracy: 0.5608 - val_loss: 1.0625 - learning_rate: 5.0000e-04\n",
      "Text embeddings: (4110, 64) (1028, 64)\n"
     ]
    }
   ],
   "source": [
    "def build_text_model(vocab_size, max_len, num_classes, embed_dim=64, rnn_units=16):\n",
    "    text_in = Input(shape=(max_len,), dtype=tf.int32, name=\"text_in\")\n",
    "\n",
    "    x = Embedding(vocab_size, embed_dim, name=\"txt_embed\")(text_in)\n",
    "    x = SimpleRNN(rnn_units,return_sequences=True, recurrent_dropout=0.1, name=\"txt_rnn\")(x)\n",
    "\n",
    "    avg_pool = GlobalAveragePooling1D(name=\"txt_gap\")(x)\n",
    "    max_pool = GlobalMaxPooling1D(name=\"txt_gmp\")(x)\n",
    "    x = Concatenate(name=\"txt_pool_concat\")([avg_pool, max_pool])\n",
    "\n",
    "    x = Dense(64, activation=\"relu\", name=\"txt_embed_dense\")(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    out = Dense(num_classes, activation=\"softmax\", name=\"txt_out\")(x)\n",
    "\n",
    "    model = Model(inputs=text_in, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "text_model = build_text_model(vocab_size, MAX_LEN, num_classes)\n",
    "text_model.summary()\n",
    "\n",
    "text_model.fit(\n",
    "    X_text_tr_pad, y_tr,\n",
    "    validation_split=0.2,\n",
    "    epochs=EPOCHS_TEXT,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=2, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor=\"val_loss\", patience=1, factor=0.5, min_lr=1e-6)\n",
    "    ],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "text_extractor = Model(\n",
    "    inputs=text_model.input,\n",
    "    outputs=text_model.get_layer(\"txt_embed_dense\").output\n",
    ")\n",
    "\n",
    "Z_txt_tr = text_extractor.predict(X_text_tr_pad, batch_size=256, verbose=0)\n",
    "Z_txt_te = text_extractor.predict(X_text_te_pad, batch_size=256, verbose=0)\n",
    "\n",
    "print(\"Text embeddings:\", Z_txt_tr.shape, Z_txt_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ffb228",
   "metadata": {},
   "source": [
    "### 6B) TABULAR model: MLP -> embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e211f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_28\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_28\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ tab_in (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ tab_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ tab_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ tab_in (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │           \u001b[38;5;34m100\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m6,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ tab_embedding (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ tab_out (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m645\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,809</span> (221.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m56,809\u001b[0m (221.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,759</span> (221.71 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m56,759\u001b[0m (221.71 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50</span> (200.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m50\u001b[0m (200.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.4398 - loss: 1.3233 - val_accuracy: 0.6034 - val_loss: 0.9532 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6074 - loss: 0.9200 - val_accuracy: 0.6825 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6615 - loss: 0.7969 - val_accuracy: 0.7287 - val_loss: 0.6545 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6977 - loss: 0.7413 - val_accuracy: 0.7287 - val_loss: 0.6347 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6931 - loss: 0.7114 - val_accuracy: 0.7530 - val_loss: 0.6081 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7235 - loss: 0.6689 - val_accuracy: 0.7470 - val_loss: 0.5912 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7269 - loss: 0.6651 - val_accuracy: 0.7543 - val_loss: 0.5776 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7251 - loss: 0.6611 - val_accuracy: 0.7603 - val_loss: 0.5664 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7287 - loss: 0.6461 - val_accuracy: 0.7616 - val_loss: 0.5716 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7330 - loss: 0.6374 - val_accuracy: 0.7628 - val_loss: 0.5563 - learning_rate: 0.0010\n",
      "Epoch 11/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7333 - loss: 0.6168 - val_accuracy: 0.7713 - val_loss: 0.5599 - learning_rate: 0.0010\n",
      "Epoch 12/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7464 - loss: 0.6083 - val_accuracy: 0.7737 - val_loss: 0.5548 - learning_rate: 0.0010\n",
      "Epoch 13/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7445 - loss: 0.6030 - val_accuracy: 0.7713 - val_loss: 0.5515 - learning_rate: 0.0010\n",
      "Epoch 14/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7360 - loss: 0.6161 - val_accuracy: 0.7676 - val_loss: 0.5590 - learning_rate: 0.0010\n",
      "Epoch 15/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7439 - loss: 0.6059 - val_accuracy: 0.7701 - val_loss: 0.5576 - learning_rate: 0.0010\n",
      "Epoch 16/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7536 - loss: 0.5847 - val_accuracy: 0.7798 - val_loss: 0.5430 - learning_rate: 5.0000e-04\n",
      "Epoch 17/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7561 - loss: 0.5797 - val_accuracy: 0.7822 - val_loss: 0.5335 - learning_rate: 5.0000e-04\n",
      "Epoch 18/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7655 - loss: 0.5605 - val_accuracy: 0.7883 - val_loss: 0.5367 - learning_rate: 5.0000e-04\n",
      "Epoch 19/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7579 - loss: 0.5727 - val_accuracy: 0.7908 - val_loss: 0.5286 - learning_rate: 5.0000e-04\n",
      "Epoch 20/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7597 - loss: 0.5629 - val_accuracy: 0.7701 - val_loss: 0.5457 - learning_rate: 5.0000e-04\n",
      "Epoch 21/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7634 - loss: 0.5524 - val_accuracy: 0.7847 - val_loss: 0.5350 - learning_rate: 5.0000e-04\n",
      "Epoch 22/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7670 - loss: 0.5606 - val_accuracy: 0.7871 - val_loss: 0.5266 - learning_rate: 2.5000e-04\n",
      "Epoch 23/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7786 - loss: 0.5446 - val_accuracy: 0.7883 - val_loss: 0.5331 - learning_rate: 2.5000e-04\n",
      "Epoch 24/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7914 - loss: 0.5216 - val_accuracy: 0.7968 - val_loss: 0.5263 - learning_rate: 2.5000e-04\n",
      "Epoch 25/25\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7850 - loss: 0.5246 - val_accuracy: 0.7968 - val_loss: 0.5232 - learning_rate: 2.5000e-04\n",
      "Tabular embeddings: (4110, 128) (1028, 128)\n"
     ]
    }
   ],
   "source": [
    "def build_tabular_model(tab_dim, num_classes):\n",
    "    tab_in = Input(shape=(tab_dim,), dtype=tf.float32, name=\"tab_in\")\n",
    "\n",
    "    x = BatchNormalization()(tab_in)\n",
    "\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    x = Dropout(0.35)(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    emb = Dense(128, activation=\"relu\", name=\"tab_embedding\")(x)\n",
    "    emb = Dropout(0.25)(emb)\n",
    "\n",
    "    out = Dense(num_classes, activation=\"softmax\", name=\"tab_out\")(emb)\n",
    "\n",
    "    model = Model(inputs=tab_in, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "tab_model = build_tabular_model(tab_dim, num_classes)\n",
    "tab_model.summary()\n",
    "\n",
    "\n",
    "tab_model.fit(\n",
    "    X_tab_tr_sc, y_tr,\n",
    "    validation_split=0.2,\n",
    "    epochs=EPOCHS_TAB,\n",
    "    batch_size=128,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor=\"val_loss\", patience=2, factor=0.5, min_lr=1e-6)\n",
    "    ],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "tab_extractor = Model(\n",
    "    inputs=tab_model.input,\n",
    "    outputs=tab_model.get_layer(\"tab_embedding\").output\n",
    ")\n",
    "\n",
    "Z_tab_tr = tab_extractor.predict(X_tab_tr_sc, batch_size=256, verbose=0)\n",
    "Z_tab_te = tab_extractor.predict(X_tab_te_sc, batch_size=256, verbose=0)\n",
    "\n",
    "print(\"Tabular embeddings:\", Z_tab_tr.shape, Z_tab_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0995792c",
   "metadata": {},
   "source": [
    "### 6C) IMAGE model: pretrained CNN + small head -> embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4786d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_image_model(num_classes):\n",
    "    base = MobileNetV2(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
    "    base.trainable = False\n",
    "\n",
    "    img_in = Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3), dtype=tf.float32, name=\"img_in\")\n",
    "    x = base(img_in)\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    x = Dropout(0.35)(x)\n",
    "\n",
    "    emb = Dense(128, activation=\"relu\", name=\"img_embedding\")(x)\n",
    "    emb = Dropout(0.25)(emb)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0rc3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
