{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2768030b",
   "metadata": {},
   "source": [
    "# Multimodal Late Fusion Model\n",
    "## Text + Tabular + Image embeddings -> SVM + XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5498683",
   "metadata": {},
   "source": [
    "## 0) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f23246ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Embedding, Bidirectional, LSTM,\n",
    "    Dense, Dropout, BatchNormalization,\n",
    "    GlobalAveragePooling1D, GlobalMaxPooling1D,\n",
    "    Concatenate\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a16b472",
   "metadata": {},
   "source": [
    "## 1) Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d9ea3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"FoodFactsCleaned.csv\")\n",
    "df[\"nutriscore_letter\"] = df[\"nutriscore_letter\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1abd7f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_COLS = [ \n",
    "    \"brand_cleaned\",\n",
    "    \"allergens_cleaned\",\n",
    "    \"ingredients_text_cleaned\",\n",
    "    \"countries_cleaned\",\n",
    "    \"additives_cleaned\",\n",
    "]\n",
    "\n",
    "TABULAR_COLS = [\n",
    "    'nova_group', 'fat_100g',\n",
    "    'saturated_fat_100g', 'carbohydrates_100g', 'sugars_100g', 'fiber_100g',\n",
    "    'proteins_100g', 'contains_palm_oil', 'vegetarian_status', 'vegan_status',\n",
    "    'nutrient_level_fat', 'nutrient_level_saturated_fat',\n",
    "    'nutrient_level_sugars', 'nutrient_level_salt', 'ecoscore_grade', 'ecoscore_score',\n",
    "    'carbon_footprint_100g', 'additives_count', 'sugar_ratio',\n",
    "    'energy_density', 'protein_ratio', 'macro_balance', 'healthy_score',\n",
    "    'log_energy_kcal_100g', 'log_salt_100g'\n",
    "]\n",
    "\n",
    "TARGET_COL = \"nutriscore_letter\"           \n",
    "IMAGE_COL = \"image_160_path\"\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# Text tokenization\n",
    "MAX_WORDS = 30000\n",
    "MAX_LEN = 200\n",
    "\n",
    "# Image settings\n",
    "IMG_SIZE = (160, 160)\n",
    "\n",
    "# NN training\n",
    "EPOCHS_TEXT = 10\n",
    "EPOCHS_TAB  = 25\n",
    "EPOCHS_IMG  = 10\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f4f1cf",
   "metadata": {},
   "source": [
    "## 2) Basic checks + building concatenated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfe39424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after filtering invalid image paths: 5138\n"
     ]
    }
   ],
   "source": [
    "needed = TEXT_COLS + TABULAR_COLS + [TARGET_COL, IMAGE_COL]\n",
    "missing = [c for c in needed if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns in df: {missing}\")\n",
    "\n",
    "for c in TEXT_COLS:\n",
    "    df[c] = df[c].fillna(\"\").astype(str)\n",
    "\n",
    "df[\"text_concat\"] = df[TEXT_COLS].agg(\" \".join, axis=1)\n",
    "\n",
    "df = df[df[IMAGE_COL].notna()].copy()\n",
    "df = df[df[IMAGE_COL].astype(str).str.len() > 0].copy()\n",
    "df = df[df[IMAGE_COL].apply(lambda p: os.path.exists(str(p)))].copy()\n",
    "\n",
    "print(\"Rows after filtering invalid image paths:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ef849e",
   "metadata": {},
   "source": [
    "## 3) Unified Data Splitting across Modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0c510b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: 5\n",
      "Train: 4110 Test: 1028\n"
     ]
    }
   ],
   "source": [
    "X_text = df[\"text_concat\"].values\n",
    "X_tab  = df[TABULAR_COLS].values.astype(np.float32)\n",
    "X_img  = df[IMAGE_COL].astype(str).values\n",
    "y_raw  = df[TARGET_COL].values\n",
    "\n",
    "if y_raw.dtype == object or isinstance(y_raw[0], str):\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y_raw)\n",
    "else:\n",
    "    y = y_raw.astype(int)\n",
    "\n",
    "num_classes = len(np.unique(y))\n",
    "print(\"Classes:\", num_classes)\n",
    "\n",
    "X_text_tr, X_text_te, X_tab_tr, X_tab_te, X_img_tr, X_img_te, y_tr, y_te = train_test_split(\n",
    "    X_text, X_tab, X_img, y,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", len(y_tr), \"Test:\", len(y_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05972b9",
   "metadata": {},
   "source": [
    "## Text & Tabular Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c77f7652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 14981\n",
      "Tab dim: 25\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_text_tr)\n",
    "\n",
    "seq_tr = tokenizer.texts_to_sequences(X_text_tr)\n",
    "seq_te = tokenizer.texts_to_sequences(X_text_te)\n",
    "\n",
    "X_text_tr_pad = pad_sequences(seq_tr, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "X_text_te_pad = pad_sequences(seq_te, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "vocab_size = min(MAX_WORDS, len(tokenizer.word_index) + 1)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_tab_tr_sc = scaler.fit_transform(X_tab_tr).astype(np.float32)\n",
    "X_tab_te_sc = scaler.transform(X_tab_te).astype(np.float32)\n",
    "\n",
    "tab_dim = X_tab_tr_sc.shape[1]\n",
    "print(\"Tab dim:\", tab_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b8420d",
   "metadata": {},
   "source": [
    "## Image loading & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2826c378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(path):\n",
    "    img_bytes = tf.io.read_file(path)\n",
    "    img = tf.io.decode_image(img_bytes, channels=3, expand_animations=False)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = mobilenet_preprocess(img)\n",
    "    return img\n",
    "\n",
    "def make_img_ds(paths, labels, batch_size=64, training=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "\n",
    "    def _map(p, y_):\n",
    "        return load_and_preprocess_image(p), y_\n",
    "    \n",
    "    ds = ds.map(_map, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if training:\n",
    "        ds = ds.shuffle(2048, seed=RANDOM_STATE, reshuffle_each_iteration=True)\n",
    "\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "img_train_ds = make_img_ds(X_img_tr, y_tr, batch_size=32, training=True)\n",
    "img_test_ds  = make_img_ds(X_img_te, y_te, batch_size=32, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb78601e",
   "metadata": {},
   "source": [
    "## 6) Modality-specific models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebc7bfc",
   "metadata": {},
   "source": [
    "### 6A) TEXT model: BiLSTM + pooling -> embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c0da18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ text_in             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_embed           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,917,568</span> │ text_in[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ txt_embed[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_gap             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ txt_rnn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_gmp             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ txt_rnn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_pool_concat     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ txt_gap[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ txt_gmp[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_embed_dense     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ txt_pool_concat[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ txt_embed_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,285</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ text_in             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_embed           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │  \u001b[38;5;34m1,917,568\u001b[0m │ text_in[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m12,352\u001b[0m │ txt_embed[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_gap             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ txt_rnn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_gmp             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ txt_rnn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_pool_concat     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ txt_gap[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ txt_gmp[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_embed_dense     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m33,024\u001b[0m │ txt_pool_concat[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ txt_embed_dense[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ txt_out (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │      \u001b[38;5;34m1,285\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,964,229</span> (7.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,964,229\u001b[0m (7.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,964,229</span> (7.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,964,229\u001b[0m (7.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 0.3157 - loss: 1.4884 - val_accuracy: 0.3017 - val_loss: 1.4740 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.3817 - loss: 1.3829 - val_accuracy: 0.3929 - val_loss: 1.4204 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.4617 - loss: 1.2665 - val_accuracy: 0.4477 - val_loss: 1.3176 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.5803 - loss: 1.0873 - val_accuracy: 0.5316 - val_loss: 1.1178 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.7138 - loss: 0.7847 - val_accuracy: 0.5535 - val_loss: 1.0472 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.8345 - loss: 0.5287 - val_accuracy: 0.5779 - val_loss: 1.0724 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.9179 - loss: 0.3212 - val_accuracy: 0.5852 - val_loss: 1.1016 - learning_rate: 5.0000e-04\n",
      "Text embeddings: (4110, 256) (1028, 256)\n"
     ]
    }
   ],
   "source": [
    "def build_text_model(vocab_size, max_len, num_classes, embed_dim=128, rnn_units=64):\n",
    "    text_in = Input(shape=(max_len,), dtype=tf.int32, name=\"text_in\")\n",
    "\n",
    "    x = Embedding(vocab_size, embed_dim, name=\"txt_embed\")(text_in)\n",
    "    x = SimpleRNN(rnn_units,return_sequences=True, name=\"txt_rnn\")(x)\n",
    "\n",
    "    avg_pool = GlobalAveragePooling1D(name=\"txt_gap\")(x)\n",
    "    max_pool = GlobalMaxPooling1D(name=\"txt_gmp\")(x)\n",
    "    x = Concatenate(name=\"txt_pool_concat\")([avg_pool, max_pool])\n",
    "\n",
    "    x = Dense(256, activation=\"relu\", name=\"txt_embed_dense\")(x)\n",
    "    x = Dropout(0.35)(x)\n",
    "\n",
    "    out = Dense(num_classes, activation=\"softmax\", name=\"txt_out\")(x)\n",
    "\n",
    "    model = Model(inputs=text_in, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "text_model = build_text_model(vocab_size, MAX_LEN, num_classes)\n",
    "text_model.summary()\n",
    "\n",
    "text_model.fit(\n",
    "    X_text_tr_pad, y_tr,\n",
    "    validation_split=0.2,\n",
    "    epochs=EPOCHS_TEXT,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=2, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor=\"val_loss\", patience=1, factor=0.5, min_lr=1e-6)\n",
    "    ],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "text_extractor = Model(\n",
    "    inputs=text_model.input,\n",
    "    outputs=text_model.get_layer(\"txt_embed_dense\").output\n",
    ")\n",
    "\n",
    "Z_txt_tr = text_extractor.predict(X_text_tr_pad, batch_size=256, verbose=0)\n",
    "Z_txt_te = text_extractor.predict(X_text_te_pad, batch_size=256, verbose=0)\n",
    "\n",
    "print(\"Text embeddings:\", Z_txt_tr.shape, Z_txt_te.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0rc3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
