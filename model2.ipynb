{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64debcc9",
   "metadata": {},
   "source": [
    "## Multimodal Early Fusion NN\n",
    "#### Complex model: BiLSTM + MultiHeadAttention + EfficientNet + Residual Dense Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9af4a073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Embedding, Bidirectional, LSTM, Dense, Dropout, Concatenate,\n",
    "    GlobalAveragePooling1D, GlobalMaxPooling1D, BatchNormalization, Add,\n",
    "    SpatialDropout1D, MultiHeadAttention, LayerNormalization\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4e7042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"FoodFactsCleaned.csv\")\n",
    "df[\"nutriscore_letter\"] = df[\"nutriscore_letter\"].astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00407167",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_COLS = [\n",
    "    \"brand_cleaned\",\n",
    "    \"allergens_cleaned\",\n",
    "    \"ingredients_text_cleaned\",\n",
    "    \"countries_cleaned\",\n",
    "    \"additives_cleaned\",\n",
    "]\n",
    "\n",
    "TABULAR_COLS = [\n",
    "    'nova_group', 'fat_100g',\n",
    "    'saturated_fat_100g', 'carbohydrates_100g', 'sugars_100g', 'fiber_100g',\n",
    "    'proteins_100g', 'contains_palm_oil', 'vegetarian_status', 'vegan_status',\n",
    "    'nutrient_level_fat', 'nutrient_level_saturated_fat',\n",
    "    'nutrient_level_sugars', 'nutrient_level_salt', 'ecoscore_grade', 'ecoscore_score',\n",
    "    'carbon_footprint_100g', 'additives_count', 'sugar_ratio',\n",
    "    'energy_density', 'protein_ratio', 'macro_balance', 'healthy_score',\n",
    "    'log_energy_kcal_100g', 'log_salt_100g'\n",
    "]\n",
    "\n",
    "TARGET_COL = \"nutriscore_letter\"       \n",
    "IMAGE_COL = \"image_160_path\"   \n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# Text tokenization\n",
    "MAX_WORDS = 30000\n",
    "MAX_LEN = 200\n",
    "\n",
    "# Image settings\n",
    "IMG_SIZE = (160, 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1db9622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: 5\n"
     ]
    }
   ],
   "source": [
    "needed = TEXT_COLS + TABULAR_COLS + [TARGET_COL, IMAGE_COL]\n",
    "# Ensure text columns are strings\n",
    "for c in TEXT_COLS:\n",
    "    df[c] = df[c].fillna(\"\").astype(str)\n",
    "\n",
    "# Concatenate text into one document per row\n",
    "df[\"text_concat\"] = df[TEXT_COLS].agg(\" \".join, axis=1)\n",
    "\n",
    "# Prepare arrays\n",
    "X_text = df[\"text_concat\"].values\n",
    "X_tab  = df[TABULAR_COLS].values.astype(np.float32)\n",
    "X_img  = df[IMAGE_COL].astype(str).values\n",
    "y = df[TARGET_COL].values\n",
    "\n",
    "num_classes = len(np.unique(y))\n",
    "print(\"Classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d162f417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3596 Val: 771 Test: 771\n"
     ]
    }
   ],
   "source": [
    "# ---- Global split: Train / Val / Test ----\n",
    "X_text_tv, X_text_te, X_tab_tv,  X_tab_te, X_img_tv,  X_img_te, y_tv, y_te = train_test_split(\n",
    "    X_text, X_tab, X_img, y,\n",
    "    test_size=0.15,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_text_tr, X_text_val, X_tab_tr,  X_tab_val, X_img_tr,  X_img_val, y_tr, y_val = train_test_split(\n",
    "    X_text_tv, X_tab_tv, X_img_tv, y_tv,\n",
    "    test_size=0.1765,   # â‰ˆ 15% of total\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_tv\n",
    ")\n",
    "\n",
    "print(\"Train:\", len(y_tr), \"Val:\", len(y_val), \"Test:\", len(y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f03461a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_text_tr)\n",
    "\n",
    "def tokenize_and_pad(texts):\n",
    "    seq = tokenizer.texts_to_sequences(texts)\n",
    "    return pad_sequences(seq, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "X_text_tr_pad  = tokenize_and_pad(X_text_tr)\n",
    "X_text_val_pad = tokenize_and_pad(X_text_val)\n",
    "X_text_te_pad  = tokenize_and_pad(X_text_te)\n",
    "\n",
    "vocab_size = min(MAX_WORDS, len(tokenizer.word_index) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59458151",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_tab_tr_sc  = scaler.fit_transform(X_tab_tr).astype(np.float32)\n",
    "X_tab_val_sc = scaler.transform(X_tab_val).astype(np.float32)\n",
    "X_tab_te_sc  = scaler.transform(X_tab_te).astype(np.float32)\n",
    "\n",
    "tab_dim = X_tab_tr_sc.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc4b05d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    img_bytes = tf.io.read_file(path)\n",
    "    img = tf.io.decode_image(img_bytes, channels=3, expand_animations=False)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = eff_preprocess(img)\n",
    "    return img\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
