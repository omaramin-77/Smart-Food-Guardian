{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86ff455b",
   "metadata": {},
   "source": [
    "### Multimodal Classification: text + tabular + image\n",
    "### Early fusion NN + Feature fusion with XGBoost and SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb5a5a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Embedding, Bidirectional, LSTM,\n",
    "    Dense, Dropout, Concatenate, GlobalAveragePooling1D\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\n",
    "from tensorflow.keras.preprocessing import image as keras_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba846842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my plan is to first perform early fusion between the tabular features and the\\n text data (using tokenized text as input). This combined representation will be fed into a suitable neural network. In parallel, the image data will be processed using a pretrained neural network to extract visual features. Finally, I will apply feature-level fusion between the learned representations from the text–tabular model and the image model, and use the fused features as input to XGBoost and SVM classifiers for final prediction.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"my plan is to first perform early fusion between the tabular features and the\n",
    " text data (using tokenized text as input). This combined representation will be fed \n",
    " into a suitable neural network. In parallel, the image data will be processed using a \n",
    " pretrained neural network to extract visual features. Finally, I will apply feature-level \n",
    " fusion between the learned representations from the text–tabular model and the image model, and use the \n",
    " fused features as input to XGBoost and SVM classifiers for final prediction.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0fb3bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"FoodFactsCleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e1b2aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_COLS = [\n",
    "    \"brand_cleaned\",\n",
    "    \"allergens_cleaned\",\n",
    "    \"ingredients_text_cleaned\",\n",
    "    \"countries_cleaned\",\n",
    "    \"additives_cleaned\",\n",
    "]\n",
    "\n",
    "TABULAR_COLS = [\n",
    "    'nova_group', 'fat_100g',\n",
    "    'saturated_fat_100g', 'carbohydrates_100g', 'sugars_100g', 'fiber_100g',\n",
    "    'proteins_100g', 'contains_palm_oil', 'vegetarian_status', 'vegan_status',\n",
    "    'nutrient_level_fat', 'nutrient_level_saturated_fat',\n",
    "    'nutrient_level_sugars', 'nutrient_level_salt', 'ecoscore_grade', 'ecoscore_score',\n",
    "    'carbon_footprint_100g', 'additives_count', 'sugar_ratio',\n",
    "    'energy_density', 'protein_ratio', 'macro_balance', 'healthy_score',\n",
    "    'log_energy_kcal_100g', 'log_salt_100g'\n",
    "]\n",
    "\n",
    "TARGET_COL = \"nutriscore_letter\"         \n",
    "IMAGE_PATH_COL = \"image_160_path\"  \n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# Text tokenization\n",
    "MAX_WORDS = 30000\n",
    "MAX_LEN = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff7ab949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after image path filtering: 5138\n"
     ]
    }
   ],
   "source": [
    "for c in TEXT_COLS:\n",
    "    df[c] = df[c].fillna(\"\").astype(str)\n",
    "\n",
    "df[\"text_concat\"] = df[TEXT_COLS].agg(\" \".join, axis=1)\n",
    "\n",
    "print(\"Rows after image path filtering:\", len(df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
